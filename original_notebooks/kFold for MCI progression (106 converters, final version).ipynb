{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel\n",
    "import nibabel.processing\n",
    "import os\n",
    "from skimage.filters import threshold_otsu\n",
    "import cc3d\n",
    "import shutil\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE SMALL GPU#\n",
    "use_gpu = 1 \n",
    "# The largest memory size GPU is always the first one (0) as they are sorted by size!\n",
    "gpus=tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(gpus[use_gpu], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the list of pMCI and sMCI. It is called mcisplit 2 because it is only split according to progression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plist=os.listdir('/local_mount/space/celer/1/users/notebooks/moises/pdata/newdata/mcisplit2/pMCI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Order them alphabetically, then shuffle (randomized kfold split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plist.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(plist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "slist=os.listdir('/local_mount/space/celer/1/users/notebooks/moises/pdata/newdata/mcisplit2/sMCI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "slist.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(slist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stablish fold folders, then copy the studies from the shuffled lists in order, the fold samples are calculated\n",
    "#using a fraction, here it is 0.20, so 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " pMCI \n",
      "\n",
      "0 136_S_0873_I204298.nii Copied to fold1\n",
      "1 116_S_1243_I41792.nii Copied to fold1\n",
      "2 021_S_0231_I12047.nii Copied to fold1\n",
      "3 035_S_0204_I12931.nii Copied to fold1\n",
      "4 141_S_1004_I282482.nii Copied to fold1\n",
      "5 009_S_1030_I29585.nii Copied to fold1\n",
      "6 007_S_0698_I23430.nii Copied to fold1\n",
      "7 033_S_0723_I20277.nii Copied to fold1\n",
      "8 027_S_0461_I26955.nii Copied to fold1\n",
      "9 100_S_1154_I71927.nii Copied to fold1\n",
      "10 005_S_0448_I225803.nii Copied to fold1\n",
      "11 057_S_1217_I40094.nii Copied to fold1\n",
      "12 007_S_0344_I13813.nii Copied to fold1\n",
      "13 006_S_1130_I221823.nii Copied to fold1\n",
      "14 013_S_0325_I17295.nii Copied to fold1\n",
      "15 018_S_0155_I12924.nii Copied to fold1\n",
      "16 005_S_0222_I12074.nii Copied to fold1\n",
      "17 057_S_1265_I39726.nii Copied to fold1\n",
      "18 116_S_1315_I48322.nii Copied to fold1\n",
      "19 128_S_0135_I192851.nii Copied to fold1\n",
      "20 137_S_0973_I33206.nii Copied to fold1\n",
      "0 126_S_1077_I35544.nii Copied to fold2\n",
      "1 003_S_1074_I171424.nii Copied to fold2\n",
      "2 136_S_0695_I27569.nii Copied to fold2\n",
      "3 127_S_1427_I73409.nii Copied to fold2\n",
      "4 098_S_0160_I12406.nii Copied to fold2\n",
      "5 031_S_0294_I26400.nii Copied to fold2\n",
      "6 033_S_0906_I27135.nii Copied to fold2\n",
      "7 018_S_0142_I11262.nii Copied to fold2\n",
      "8 041_S_1425_I72658.nii Copied to fold2\n",
      "9 033_S_0513_I19372.nii Copied to fold2\n",
      "10 013_S_0860_I30124.nii Copied to fold2\n",
      "11 027_S_0408_I26953.nii Copied to fold2\n",
      "12 073_S_0909_I32583.nii Copied to fold2\n",
      "13 033_S_0567_I17165.nii Copied to fold2\n",
      "14 041_S_1010_I45280.nii Copied to fold2\n",
      "15 126_S_0865_I30553.nii Copied to fold2\n",
      "16 041_S_0549_I20366.nii Copied to fold2\n",
      "17 036_S_0976_I35548.nii Copied to fold2\n",
      "18 013_S_1186_I42880.nii Copied to fold2\n",
      "19 127_S_0394_I18767.nii Copied to fold2\n",
      "20 130_S_0285_I225718.nii Copied to fold2\n",
      "0 013_S_0240_I28950.nii Copied to fold3\n",
      "1 036_S_1135_I36214.nii Copied to fold3\n",
      "2 137_S_0994_I32055.nii Copied to fold3\n",
      "3 100_S_0995_I54611.nii Copied to fold3\n",
      "4 035_S_0292_I14203.nii Copied to fold3\n",
      "5 041_S_1412_I70184.nii Copied to fold3\n",
      "6 033_S_1116_I205053.nii Copied to fold3\n",
      "7 027_S_0256_I26950.nii Copied to fold3\n",
      "8 127_S_0112_I15262.nii Copied to fold3\n",
      "9 005_S_1224_I40612.nii Copied to fold3\n",
      "10 027_S_0835_I266911.nii Copied to fold3\n",
      "11 016_S_1117_I183352.nii Copied to fold3\n",
      "12 016_S_1326_I312617.nii Copied to fold3\n",
      "13 011_S_0326_I13808.nii Copied to fold3\n",
      "14 005_S_0572_I211079.nii Copied to fold3\n",
      "15 037_S_1078_I209206.nii Copied to fold3\n",
      "16 041_S_1423_I73983.nii Copied to fold3\n",
      "17 100_S_1226_I221694.nii Copied to fold3\n",
      "18 057_S_0941_I27433.nii Copied to fold3\n",
      "19 094_S_1398_I56520.nii Copied to fold3\n",
      "20 014_S_0563_I196086.nii Copied to fold3\n",
      "0 098_S_0667_I193491.nii Copied to fold4\n",
      "1 126_S_0708_I23475.nii Copied to fold4\n",
      "2 007_S_0128_I20483.nii Copied to fold4\n",
      "3 016_S_0702_I193103.nii Copied to fold4\n",
      "4 098_S_0269_I241729.nii Copied to fold4\n",
      "5 941_S_1311_I76467.nii Copied to fold4\n",
      "6 011_S_0861_I26521.nii Copied to fold4\n",
      "7 007_S_0101_I9904.nii Copied to fold4\n",
      "8 052_S_0671_I243795.nii Copied to fold4\n",
      "9 011_S_1282_I44227.nii Copied to fold4\n",
      "10 128_S_1043_I272435.nii Copied to fold4\n",
      "11 037_S_0566_I260904.nii Copied to fold4\n",
      "12 057_S_1007_I29480.nii Copied to fold4\n",
      "13 035_S_0997_I36328.nii Copied to fold4\n",
      "14 116_S_0361_I15903.nii Copied to fold4\n",
      "15 130_S_0289_I228746.nii Copied to fold4\n",
      "16 002_S_1268_I228411.nii Copied to fold4\n",
      "17 127_S_1032_I32437.nii Copied to fold4\n",
      "18 100_S_0930_I53036.nii Copied to fold4\n",
      "19 941_S_1295_I69881.nii Copied to fold4\n",
      "20 114_S_1106_I33508.nii Copied to fold4\n",
      "0 024_S_1393_I49954.nii Copied to fold5\n",
      "1 033_S_0511_I17296.nii Copied to fold5\n",
      "2 128_S_0227_I312075.nii Copied to fold5\n",
      "3 014_S_0658_I202817.nii Copied to fold5\n",
      "4 003_S_1057_I223690.nii Copied to fold5\n",
      "5 021_S_0626_I20198.nii Copied to fold5\n",
      "6 100_S_0892_I51323.nii Copied to fold5\n",
      "7 018_S_0080_I11044.nii Copied to fold5\n",
      "8 029_S_1318_I141742.nii Copied to fold5\n",
      "9 036_S_1240_I44117.nii Copied to fold5\n",
      "10 036_S_0945_I29098.nii Copied to fold5\n",
      "11 018_S_0057_I11042.nii Copied to fold5\n",
      "12 002_S_0729_I187916.nii Copied to fold5\n",
      "13 068_S_0872_I282989.nii Copied to fold5\n",
      "14 127_S_0925_I29343.nii Copied to fold5\n",
      "15 031_S_0830_I194250.nii Copied to fold5\n",
      "16 116_S_0834_I201222.nii Copied to fold5\n",
      "17 041_S_0314_I14488.nii Copied to fold5\n",
      "18 032_S_0214_I12440.nii Copied to fold5\n",
      "19 012_S_1033_I31433.nii Copied to fold5\n",
      "20 021_S_0141_I20254.nii Copied to fold5\n",
      "21 037_S_0552_I240801.nii Copied to fold5\n",
      "\n",
      " sMCI \n",
      "\n",
      "0 002_S_1155_I209934.nii Copied to fold1\n",
      "1 168_S_6180_I983061.nii Copied to fold1\n",
      "2 033_S_6697_I1157339.nii Copied to fold1\n",
      "3 121_S_1322_I44921.nii Copied to fold1\n",
      "4 007_S_0293_I12556.nii Copied to fold1\n",
      "5 027_S_6002_I829731.nii Copied to fold1\n",
      "6 006_S_6682_I1157533.nii Copied to fold1\n",
      "7 168_S_6860_I1325690.nii Copied to fold1\n",
      "8 941_S_6052_I878910.nii Copied to fold1\n",
      "9 031_S_0554_I16828.nii Copied to fold1\n",
      "10 141_S_6041_I892843.nii Copied to fold1\n",
      "11 036_S_6894_I1381501.nii Copied to fold1\n",
      "12 009_S_1199_I37964.nii Copied to fold1\n",
      "13 041_S_1411_I76843.nii Copied to fold1\n",
      "14 027_S_0485_I26957.nii Copied to fold1\n",
      "15 037_S_6083_I938655.nii Copied to fold1\n",
      "16 027_S_6034_I908623.nii Copied to fold1\n",
      "17 041_S_0407_I16606.nii Copied to fold1\n",
      "18 037_S_6222_I1021093.nii Copied to fold1\n",
      "19 006_S_6243_I984045.nii Copied to fold1\n",
      "20 168_S_6467_I1034450.nii Copied to fold1\n",
      "21 027_S_6961_I1465066.nii Copied to fold1\n",
      "22 037_S_0150_I257571.nii Copied to fold1\n",
      "23 003_S_6606_I1115026.nii Copied to fold1\n",
      "24 070_S_6236_I972920.nii Copied to fold1\n",
      "25 109_S_0950_I29821.nii Copied to fold1\n",
      "26 027_S_1045_I209627.nii Copied to fold1\n",
      "27 130_S_0505_I355896.nii Copied to fold1\n",
      "28 153_S_6633_I1090964.nii Copied to fold1\n",
      "29 301_S_6811_I1265032.nii Copied to fold1\n",
      "30 116_S_6428_I1024238.nii Copied to fold1\n",
      "31 035_S_0033_I16117.nii Copied to fold1\n",
      "32 041_S_0598_I20051.nii Copied to fold1\n",
      "33 070_S_6229_I975597.nii Copied to fold1\n",
      "34 016_S_6789_I1243165.nii Copied to fold1\n",
      "35 116_S_6775_I1234267.nii Copied to fold1\n",
      "36 003_S_6479_I1065559.nii Copied to fold1\n",
      "37 168_S_6591_I1158154.nii Copied to fold1\n",
      "38 135_S_6622_I1080300.nii Copied to fold1\n",
      "39 019_S_6315_I997787.nii Copied to fold1\n",
      "40 005_S_0546_I17723.nii Copied to fold1\n",
      "41 057_S_0464_I17214.nii Copied to fold1\n",
      "42 135_S_6544_I1050687.nii Copied to fold1\n",
      "43 012_S_6503_I1074989.nii Copied to fold1\n",
      "44 003_S_6268_I1043763.nii Copied to fold1\n",
      "45 137_S_0481_I16489.nii Copied to fold1\n",
      "46 129_S_6852_I1296763.nii Copied to fold1\n",
      "47 073_S_1357_I57533.nii Copied to fold1\n",
      "48 021_S_0424_I15015.nii Copied to fold1\n",
      "49 094_S_1314_I47877.nii Copied to fold1\n",
      "50 130_S_6612_I1092135.nii Copied to fold1\n",
      "51 012_S_1175_I36789.nii Copied to fold1\n",
      "52 109_S_6300_I1147901.nii Copied to fold1\n",
      "0 109_S_6373_I1122764.nii Copied to fold2\n",
      "1 037_S_6141_I985518.nii Copied to fold2\n",
      "2 301_S_6297_I997358.nii Copied to fold2\n",
      "3 033_S_6889_I1352014.nii Copied to fold2\n",
      "4 053_S_6598_I1063018.nii Copied to fold2\n",
      "5 027_S_6788_I1213971.nii Copied to fold2\n",
      "6 130_S_6604_I1072720.nii Copied to fold2\n",
      "7 003_S_6432_I1024803.nii Copied to fold2\n",
      "8 024_S_6846_I1283729.nii Copied to fold2\n",
      "9 027_S_6640_I1115635.nii Copied to fold2\n",
      "10 067_S_6525_I1183348.nii Copied to fold2\n",
      "11 012_S_0720_I23221.nii Copied to fold2\n",
      "12 137_S_6883_I1419002.nii Copied to fold2\n",
      "13 036_S_0673_I20471.nii Copied to fold2\n",
      "14 037_S_0377_I217256.nii Copied to fold2\n",
      "15 341_S_6605_I1080531.nii Copied to fold2\n",
      "16 006_S_6291_I1003431.nii Copied to fold2\n",
      "17 041_S_1260_I43223.nii Copied to fold2\n",
      "18 109_S_6221_I1122085.nii Copied to fold2\n",
      "19 027_S_0307_I256050.nii Copied to fold2\n",
      "20 019_S_6483_I1029236.nii Copied to fold2\n",
      "21 109_S_6364_I1122188.nii Copied to fold2\n",
      "22 006_S_6441_I1039164.nii Copied to fold2\n",
      "23 053_S_0919_I267656.nii Copied to fold2\n",
      "24 035_S_6947_I1462465.nii Copied to fold2\n",
      "25 141_S_1255_I227044.nii Copied to fold2\n",
      "26 141_S_1052_I286096.nii Copied to fold2\n",
      "27 032_S_6804_I1255537.nii Copied to fold2\n",
      "28 137_S_0825_I27700.nii Copied to fold2\n",
      "29 305_S_6877_I1344496.nii Copied to fold2\n",
      "30 127_S_6512_I1054468.nii Copied to fold2\n",
      "31 007_S_0414_I17314.nii Copied to fold2\n",
      "32 073_S_0746_I43238.nii Copied to fold2\n",
      "33 019_S_6757_I1185225.nii Copied to fold2\n",
      "34 153_S_6336_I1005313.nii Copied to fold2\n",
      "35 053_S_6861_I1362224.nii Copied to fold2\n",
      "36 301_S_6777_I1223180.nii Copied to fold2\n",
      "37 013_S_1275_I44970.nii Copied to fold2\n",
      "38 019_S_6533_I1045673.nii Copied to fold2\n",
      "39 127_S_6241_I1007624.nii Copied to fold2\n",
      "40 941_S_6068_I900236.nii Copied to fold2\n",
      "41 029_S_6798_I1269654.nii Copied to fold2\n",
      "42 129_S_6830_I1257732.nii Copied to fold2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 305_S_6378_I1043319.nii Copied to fold2\n",
      "44 036_S_6887_I1349346.nii Copied to fold2\n",
      "45 021_S_0178_I11707.nii Copied to fold2\n",
      "46 305_S_6498_I1053659.nii Copied to fold2\n",
      "47 036_S_0656_I19783.nii Copied to fold2\n",
      "48 168_S_6634_I1136677.nii Copied to fold2\n",
      "49 341_S_6686_I1147777.nii Copied to fold2\n",
      "50 109_S_6220_I1122762.nii Copied to fold2\n",
      "51 041_S_0446_I16416.nii Copied to fold2\n",
      "52 041_S_0721_I24979.nii Copied to fold2\n",
      "0 006_S_6770_I1225564.nii Copied to fold3\n",
      "1 168_S_6619_I1122761.nii Copied to fold3\n",
      "2 137_S_6693_I1267099.nii Copied to fold3\n",
      "3 114_S_0410_I27453.nii Copied to fold3\n",
      "4 020_S_6901_I1420623.nii Copied to fold3\n",
      "5 051_S_6719_I1184831.nii Copied to fold3\n",
      "6 114_S_1103_I34083.nii Copied to fold3\n",
      "7 126_S_0709_I20549.nii Copied to fold3\n",
      "8 141_S_1378_I55188.nii Copied to fold3\n",
      "9 137_S_1414_I72117.nii Copied to fold3\n",
      "10 130_S_6823_I1276464.nii Copied to fold3\n",
      "11 129_S_6848_I1293000.nii Copied to fold3\n",
      "12 098_S_6534_I1061739.nii Copied to fold3\n",
      "13 099_S_6632_I1117860.nii Copied to fold3\n",
      "14 128_S_1408_I200599.nii Copied to fold3\n",
      "15 003_S_1122_I222882.nii Copied to fold3\n",
      "16 305_S_6899_I1415873.nii Copied to fold3\n",
      "17 137_S_0158_I12120.nii Copied to fold3\n",
      "18 126_S_1187_I284312.nii Copied to fold3\n",
      "19 301_S_6615_I1080183.nii Copied to fold3\n",
      "20 016_S_6800_I1241315.nii Copied to fold3\n",
      "21 305_S_6744_I1209690.nii Copied to fold3\n",
      "22 141_S_6075_I921120.nii Copied to fold3\n",
      "23 941_S_6803_I1238836.nii Copied to fold3\n",
      "24 027_S_6463_I1062326.nii Copied to fold3\n",
      "25 052_S_0989_I213447.nii Copied to fold3\n",
      "26 018_S_6414_I1043696.nii Copied to fold3\n",
      "27 035_S_6480_I1024012.nii Copied to fold3\n",
      "28 128_S_0770_I152809.nii Copied to fold3\n",
      "29 116_S_6550_I1038365.nii Copied to fold3\n",
      "30 016_S_6926_I1480980.nii Copied to fold3\n",
      "31 168_S_6874_I1326426.nii Copied to fold3\n",
      "32 006_S_6674_I1165048.nii Copied to fold3\n",
      "33 012_S_0917_I33676.nii Copied to fold3\n",
      "34 011_S_6618_I1128651.nii Copied to fold3\n",
      "35 003_S_0908_I223689.nii Copied to fold3\n",
      "36 031_S_0867_I208290.nii Copied to fold3\n",
      "37 014_S_6944_I1483802.nii Copied to fold3\n",
      "38 137_S_6880_I1425020.nii Copied to fold3\n",
      "39 141_S_6779_I1223141.nii Copied to fold3\n",
      "40 013_S_1120_I31383.nii Copied to fold3\n",
      "41 137_S_6654_I1160601.nii Copied to fold3\n",
      "42 130_S_6047_I884461.nii Copied to fold3\n",
      "43 029_S_1218_I221994.nii Copied to fold3\n",
      "44 137_S_0722_I23218.nii Copied to fold3\n",
      "45 114_S_0378_I29035.nii Copied to fold3\n",
      "46 002_S_6652_I1158636.nii Copied to fold3\n",
      "47 057_S_1269_I218278.nii Copied to fold3\n",
      "48 022_S_0544_I17557.nii Copied to fold3\n",
      "49 128_S_0138_I274012.nii Copied to fold3\n",
      "50 006_S_6651_I1140899.nii Copied to fold3\n",
      "51 168_S_6875_I1364446.nii Copied to fold3\n",
      "52 019_S_6668_I1130202.nii Copied to fold3\n",
      "0 041_S_6731_I1190810.nii Copied to fold4\n",
      "1 006_S_6672_I1142627.nii Copied to fold4\n",
      "2 070_S_6911_I1438641.nii Copied to fold4\n",
      "3 126_S_6724_I1178514.nii Copied to fold4\n",
      "4 114_S_1118_I34543.nii Copied to fold4\n",
      "5 003_S_6954_I1499518.nii Copied to fold4\n",
      "6 305_S_6742_I1209838.nii Copied to fold4\n",
      "7 130_S_6329_I1024828.nii Copied to fold4\n",
      "8 006_S_6610_I1075932.nii Copied to fold4\n",
      "9 041_S_0679_I20162.nii Copied to fold4\n",
      "10 051_S_1072_I285110.nii Copied to fold4\n",
      "11 016_S_6771_I1260305.nii Copied to fold4\n",
      "12 037_S_6125_I961087.nii Copied to fold4\n",
      "13 135_S_6446_I1019812.nii Copied to fold4\n",
      "14 128_S_0200_I1080246.nii Copied to fold4\n",
      "15 024_S_1400_I55794.nii Copied to fold4\n",
      "16 006_S_6657_I1140902.nii Copied to fold4\n",
      "17 022_S_6847_I1287387.nii Copied to fold4\n",
      "18 109_S_1114_I35600.nii Copied to fold4\n",
      "19 010_S_6748_I1193424.nii Copied to fold4\n",
      "20 141_S_6964_I1480309.nii Copied to fold4\n",
      "21 109_S_1343_I78293.nii Copied to fold4\n",
      "22 021_S_6890_I1386676.nii Copied to fold4\n",
      "23 012_S_0932_I28493.nii Copied to fold4\n",
      "24 130_S_6688_I1141224.nii Copied to fold4\n",
      "25 036_S_6878_I1328823.nii Copied to fold4\n",
      "26 127_S_1419_I71273.nii Copied to fold4\n",
      "27 036_S_6897_I1450142.nii Copied to fold4\n",
      "28 032_S_6700_I1242413.nii Copied to fold4\n",
      "29 016_S_6809_I1237158.nii Copied to fold4\n",
      "30 005_S_6427_I1029563.nii Copied to fold4\n",
      "31 131_S_6805_I1268415.nii Copied to fold4\n",
      "32 035_S_6641_I1117556.nii Copied to fold4\n",
      "33 168_S_6426_I1023676.nii Copied to fold4\n",
      "34 114_S_6597_I1138713.nii Copied to fold4\n",
      "35 016_S_6939_I1473538.nii Copied to fold4\n",
      "36 024_S_6033_I872299.nii Copied to fold4\n",
      "37 168_S_6541_I1067624.nii Copied to fold4\n",
      "38 129_S_6857_I1316777.nii Copied to fold4\n",
      "39 098_S_6707_I1192255.nii Copied to fold4\n",
      "40 130_S_6611_I1133154.nii Copied to fold4\n",
      "41 153_S_6450_I1027402.nii Copied to fold4\n",
      "42 128_S_0225_I200597.nii Copied to fold4\n",
      "43 137_S_0669_I23219.nii Copied to fold4\n",
      "44 019_S_6635_I1122508.nii Copied to fold4\n",
      "45 006_S_6677_I1228527.nii Copied to fold4\n",
      "46 027_S_6643_I1121790.nii Copied to fold4\n",
      "47 041_S_1418_I59451.nii Copied to fold4\n",
      "48 131_S_0409_I38227.nii Copied to fold4\n",
      "49 068_S_0802_I916314.nii Copied to fold4\n",
      "50 027_S_0644_I242306.nii Copied to fold4\n",
      "51 003_S_6258_I996084.nii Copied to fold4\n",
      "52 941_S_6345_I1004761.nii Copied to fold4\n",
      "0 012_S_6073_I916397.nii Copied to fold5\n",
      "1 131_S_6143_I1013164.nii Copied to fold5\n",
      "2 057_S_0957_I28850.nii Copied to fold5\n",
      "3 006_S_6696_I1181907.nii Copied to fold5\n",
      "4 135_S_6110_I941040.nii Copied to fold5\n",
      "5 305_S_6871_I1321238.nii Copied to fold5\n",
      "6 137_S_0443_I20741.nii Copied to fold5\n",
      "7 136_S_0107_I239482.nii Copied to fold5\n",
      "8 037_S_6627_I1136170.nii Copied to fold5\n",
      "9 099_S_6691_I1380833.nii Copied to fold5\n",
      "10 052_S_1346_I58166.nii Copied to fold5\n",
      "11 041_S_0282_I15580.nii Copied to fold5\n",
      "12 094_S_1188_I38073.nii Copied to fold5\n",
      "13 013_S_6206_I1035545.nii Copied to fold5\n",
      "14 100_S_0296_I240472.nii Copied to fold5\n",
      "15 051_S_6761_I1188820.nii Copied to fold5\n",
      "16 109_S_6376_I1122086.nii Copied to fold5\n",
      "17 141_S_1245_I108910.nii Copied to fold5\n",
      "18 016_S_0354_I17384.nii Copied to fold5\n",
      "19 098_S_6593_I1122791.nii Copied to fold5\n",
      "20 014_S_6765_I1227192.nii Copied to fold5\n",
      "21 022_S_6863_I1333377.nii Copied to fold5\n",
      "22 067_S_6529_I1059604.nii Copied to fold5\n",
      "23 137_S_0800_I23686.nii Copied to fold5\n",
      "24 168_S_6821_I1291544.nii Copied to fold5\n",
      "25 006_S_6252_I995001.nii Copied to fold5\n",
      "26 135_S_6703_I1152634.nii Copied to fold5\n",
      "27 135_S_6586_I1063261.nii Copied to fold5\n",
      "28 094_S_0531_I20285.nii Copied to fold5\n",
      "29 012_S_1165_I36389.nii Copied to fold5\n",
      "30 006_S_6727_I1175074.nii Copied to fold5\n",
      "31 029_S_6726_I1196095.nii Copied to fold5\n",
      "32 036_S_6916_I1430127.nii Copied to fold5\n",
      "33 012_S_6760_I1192872.nii Copied to fold5\n",
      "34 127_S_1210_I41570.nii Copied to fold5\n",
      "35 012_S_0634_I20175.nii Copied to fold5\n",
      "36 041_S_1420_I78357.nii Copied to fold5\n",
      "37 036_S_6885_I1343472.nii Copied to fold5\n",
      "38 153_S_6274_I984660.nii Copied to fold5\n",
      "39 094_S_1417_I65420.nii Copied to fold5\n",
      "40 341_S_6764_I1218966.nii Copied to fold5\n",
      "41 067_S_6474_I1037264.nii Copied to fold5\n",
      "42 301_S_6056_I938779.nii Copied to fold5\n",
      "43 011_S_0362_I14183.nii Copied to fold5\n",
      "44 033_S_6497_I1025067.nii Copied to fold5\n",
      "45 305_S_6845_I1286989.nii Copied to fold5\n",
      "46 036_S_0748_I23770.nii Copied to fold5\n",
      "47 002_S_6695_I1152976.nii Copied to fold5\n",
      "48 022_S_6716_I1214884.nii Copied to fold5\n",
      "49 052_S_1352_I232217.nii Copied to fold5\n",
      "50 027_S_6842_I1299327.nii Copied to fold5\n",
      "51 016_S_0590_I19302.nii Copied to fold5\n",
      "52 137_S_1426_I78258.nii Copied to fold5\n",
      "53 137_S_0668_I194243.nii Copied to fold5\n",
      "54 006_S_6681_I1149896.nii Copied to fold5\n"
     ]
    }
   ],
   "source": [
    "fold1=\"/local_mount/space/celer/1/users/notebooks/moises/pdata/newdata/kfold2/fold1\"\n",
    "fold2=\"/local_mount/space/celer/1/users/notebooks/moises/pdata/newdata/kfold2/fold2\"\n",
    "fold3=\"/local_mount/space/celer/1/users/notebooks/moises/pdata/newdata/kfold2/fold3\"\n",
    "fold4=\"/local_mount/space/celer/1/users/notebooks/moises/pdata/newdata/kfold2/fold4\"\n",
    "fold5=\"/local_mount/space/celer/1/users/notebooks/moises/pdata/newdata/kfold2/fold5\"\n",
    "\n",
    "#Loop for pMCI\n",
    "\n",
    "print(\"\\n pMCI \\n\")\n",
    "\n",
    "os.chdir(\"/local_mount/space/celer/1/users/notebooks/moises/pdata/newdata/mcisplit2/pMCI\")\n",
    "\n",
    "fold_samples=round(0.2*len(plist))\n",
    "\n",
    "f1=plist[:fold_samples]\n",
    "f2=plist[fold_samples:(2*fold_samples)]\n",
    "f3=plist[(2*fold_samples):(3*fold_samples)]\n",
    "f4=plist[(3*fold_samples):(4*fold_samples)]\n",
    "f5=plist[(4*fold_samples):]\n",
    "\n",
    "for i,j in enumerate(f1):\n",
    "    shutil.copy(j,\"{0}/pMCI\".format(fold1))\n",
    "    print(i,j, \"Copied to fold1\")\n",
    "    \n",
    "for i,j in enumerate(f2):\n",
    "    shutil.copy(j,\"{0}/pMCI\".format(fold2))\n",
    "    print(i,j, \"Copied to fold2\")\n",
    "    \n",
    "for i,j in enumerate(f3):\n",
    "    shutil.copy(j,\"{0}/pMCI\".format(fold3))\n",
    "    print(i,j, \"Copied to fold3\")\n",
    "    \n",
    "for i,j in enumerate(f4):\n",
    "    shutil.copy(j,\"{0}/pMCI\".format(fold4))\n",
    "    print(i,j, \"Copied to fold4\")\n",
    "    \n",
    "for i,j in enumerate(f5):\n",
    "    shutil.copy(j,\"{0}/pMCI\".format(fold5))\n",
    "    print(i,j, \"Copied to fold5\")\n",
    "\n",
    "    \n",
    "#Loop for sMCI\n",
    "\n",
    "print(\"\\n sMCI \\n\")\n",
    "\n",
    "os.chdir(\"/local_mount/space/celer/1/users/notebooks/moises/pdata/newdata/mcisplit2/sMCI\")\n",
    "\n",
    "fold_samples=round(0.2*len(slist))\n",
    "\n",
    "f1=slist[:fold_samples]\n",
    "f2=slist[fold_samples:(2*fold_samples)]\n",
    "f3=slist[(2*fold_samples):(3*fold_samples)]\n",
    "f4=slist[(3*fold_samples):(4*fold_samples)]\n",
    "f5=slist[(4*fold_samples):]\n",
    "\n",
    "for i,j in enumerate(f1):\n",
    "    shutil.copy(j,\"{0}/sMCI\".format(fold1))\n",
    "    print(i,j, \"Copied to fold1\")\n",
    "    \n",
    "for i,j in enumerate(f2):\n",
    "    shutil.copy(j,\"{0}/sMCI\".format(fold2))\n",
    "    print(i,j, \"Copied to fold2\")\n",
    "    \n",
    "for i,j in enumerate(f3):\n",
    "    shutil.copy(j,\"{0}/sMCI\".format(fold3))\n",
    "    print(i,j, \"Copied to fold3\")\n",
    "    \n",
    "for i,j in enumerate(f4):\n",
    "    shutil.copy(j,\"{0}/sMCI\".format(fold4))\n",
    "    print(i,j, \"Copied to fold4\")\n",
    "    \n",
    "for i,j in enumerate(f5):\n",
    "    shutil.copy(j,\"{0}/sMCI\".format(fold5))\n",
    "    print(i,j, \"Copied to fold5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "292"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(slist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Min-max scaling between 0 and 1\n",
    "def normalize(volume):\n",
    "    \"\"\"Normalize the volume\"\"\"\n",
    "    min = volume.min()\n",
    "    max = volume.max()\n",
    "    volume = (volume - min) / (max - min)\n",
    "    volume = volume.astype(\"float32\")\n",
    "    return volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is similar to Ding's preprocess, except CCA is performed in 3D and the largest label is the one we keep\n",
    "\n",
    "def pp(original_image):\n",
    "    \n",
    "    input_img=input_img = nibabel.load(\"{0}\".format(original_image))\n",
    "    resampled_img = nibabel.processing.conform(input_img, out_shape=(100,100,90), voxel_size=(2.0, 2.0, 2.0))\n",
    "    \n",
    "    img = resampled_img.get_fdata()\n",
    "    \n",
    "    thresh = threshold_otsu(img)\n",
    "    bw_img1 = np.copy(img)\n",
    "    bw_img1[bw_img1 < thresh] = 0\n",
    "    bw_img1[bw_img1 >= thresh] = 255\n",
    "    \n",
    "    input_CCA=bw_img1.astype('int32')\n",
    "    connectivity = 6\n",
    "    labels_out, N = cc3d.connected_components(input_CCA, return_N=True)\n",
    "    \n",
    "    def mask_largest_label (labels_out, N):\n",
    "        #print(\"This function returns the largest blob of a CCA processed image as a binary mask\")\n",
    "        #print(\"\")\n",
    "        def separate_labels(label_ID, label_matrix):\n",
    "            mask=1*(label_matrix == label_ID)\n",
    "            return mask\n",
    "        labellist=[]\n",
    "        for j in range(1, N+1):\n",
    "            a=separate_labels(j, labels_out)\n",
    "            labellist.append(a)\n",
    "        #print(\"The image has {0} labels\".format(len(labellist)))\n",
    "        z=labellist[0]\n",
    "        #print(\"The shape of the labels is: {0}\".format(z.shape))\n",
    "        sizelist=[]\n",
    "        for counter,element in enumerate (labellist):\n",
    "            a=labellist[counter].sum()\n",
    "            sizelist.append(a)\n",
    "        #print(\"Label sizes: {0}\".format(sizelist))\n",
    "        sizelist=np.asarray(sizelist)\n",
    "        a=sizelist.argmax()\n",
    "        #print(\"The largest label index is: {0}\".format(a))\n",
    "        mask=labellist[a]\n",
    "        #print(\"The largest label is now a binary mask with shape {0}, size {1}, max value {2} and min value {3}\".format((mask.shape),(mask.sum()),(mask.max()),(mask.min())))\n",
    "        return mask\n",
    "\n",
    "    mask=mask_largest_label(labels_out, N)\n",
    "    \n",
    "    pimg=np.multiply(img,mask)\n",
    "    \n",
    "    return pimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrapper function for normalize and preprocess\n",
    "\n",
    "def process_scan(path):\n",
    "    \"\"\"Read and normalize volume\"\"\"\n",
    "    # Read and pp scan\n",
    "    volume = pp(path)\n",
    "    # Normalize\n",
    "    volume = normalize(volume)\n",
    "    return volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/local_mount/space/celer/1/users/notebooks/moises\n"
     ]
    }
   ],
   "source": [
    "cd /local_mount/space/celer/1/users/notebooks/moises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3D preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_sMCI_scan_paths = [\n",
    "    os.path.join(os.getcwd(), \"pdata/newdata/kfold2/fold1/sMCI\", x)\n",
    "    for x in os.listdir(\"pdata/newdata/kfold2/fold1/sMCI\")]\n",
    "\n",
    "f2_sMCI_scan_paths = [\n",
    "    os.path.join(os.getcwd(), \"pdata/newdata/kfold2/fold2/sMCI\", x)\n",
    "    for x in os.listdir(\"pdata/newdata/kfold2/fold2/sMCI\")]\n",
    "    \n",
    "f3_sMCI_scan_paths = [\n",
    "    os.path.join(os.getcwd(), \"pdata/newdata/kfold2/fold3/sMCI\", x)\n",
    "    for x in os.listdir(\"pdata/newdata/kfold2/fold3/sMCI\")]\n",
    "    \n",
    "f4_sMCI_scan_paths = [\n",
    "    os.path.join(os.getcwd(), \"pdata/newdata/kfold2/fold4/sMCI\", x)\n",
    "    for x in os.listdir(\"pdata/newdata/kfold2/fold4/sMCI\")]\n",
    "    \n",
    "f5_sMCI_scan_paths = [\n",
    "    os.path.join(os.getcwd(), \"pdata/newdata/kfold2/fold5/sMCI\", x)\n",
    "    for x in os.listdir(\"pdata/newdata/kfold2/fold5/sMCI\")]\n",
    "\n",
    "    \n",
    "f1_pMCI_scan_paths = [\n",
    "    os.path.join(os.getcwd(), \"pdata/newdata/kfold2/fold1/pMCI\", x)\n",
    "    for x in os.listdir(\"pdata/newdata/kfold2/fold1/pMCI\")]\n",
    "\n",
    "f2_pMCI_scan_paths = [\n",
    "    os.path.join(os.getcwd(), \"pdata/newdata/kfold2/fold2/pMCI\", x)\n",
    "    for x in os.listdir(\"pdata/newdata/kfold2/fold2/pMCI\")]\n",
    "\n",
    "f3_pMCI_scan_paths = [\n",
    "    os.path.join(os.getcwd(), \"pdata/newdata/kfold2/fold3/pMCI\", x)\n",
    "    for x in os.listdir(\"pdata/newdata/kfold2/fold3/pMCI\")]\n",
    "\n",
    "f4_pMCI_scan_paths = [\n",
    "    os.path.join(os.getcwd(), \"pdata/newdata/kfold2/fold4/pMCI\", x)\n",
    "    for x in os.listdir(\"pdata/newdata/kfold2/fold4/pMCI\")]\n",
    "\n",
    "f5_pMCI_scan_paths = [\n",
    "    os.path.join(os.getcwd(), \"pdata/newdata/kfold2/fold5/pMCI\", x)\n",
    "    for x in os.listdir(\"pdata/newdata/kfold2/fold5/pMCI\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Process scans for each fold\n",
    "f1_pMCI_scans = np.array([process_scan(path) for path in f1_pMCI_scan_paths])\n",
    "f2_pMCI_scans = np.array([process_scan(path) for path in f2_pMCI_scan_paths])\n",
    "f3_pMCI_scans = np.array([process_scan(path) for path in f3_pMCI_scan_paths])\n",
    "f4_pMCI_scans = np.array([process_scan(path) for path in f4_pMCI_scan_paths])\n",
    "f5_pMCI_scans = np.array([process_scan(path) for path in f5_pMCI_scan_paths])\n",
    "\n",
    "f1_sMCI_scans = np.array([process_scan(path) for path in f1_sMCI_scan_paths])\n",
    "f2_sMCI_scans = np.array([process_scan(path) for path in f2_sMCI_scan_paths])\n",
    "f3_sMCI_scans = np.array([process_scan(path) for path in f3_sMCI_scan_paths])\n",
    "f4_sMCI_scans = np.array([process_scan(path) for path in f4_sMCI_scan_paths])\n",
    "f5_sMCI_scans = np.array([process_scan(path) for path in f5_sMCI_scan_paths])\n",
    "\n",
    "\n",
    "# # Labeling samples according to folder architecture\n",
    "f1_pMCI_labels = np.array([1 for _ in range(len(f1_pMCI_scans))])\n",
    "f2_pMCI_labels = np.array([1 for _ in range(len(f2_pMCI_scans))])\n",
    "f3_pMCI_labels = np.array([1 for _ in range(len(f3_pMCI_scans))])\n",
    "f4_pMCI_labels = np.array([1 for _ in range(len(f4_pMCI_scans))])\n",
    "f5_pMCI_labels = np.array([1 for _ in range(len(f5_pMCI_scans))])\n",
    "\n",
    "f1_sMCI_labels = np.array([0 for _ in range(len(f1_sMCI_scans))])\n",
    "f2_sMCI_labels = np.array([0 for _ in range(len(f2_sMCI_scans))])\n",
    "f3_sMCI_labels = np.array([0 for _ in range(len(f3_sMCI_scans))])\n",
    "f4_sMCI_labels = np.array([0 for _ in range(len(f4_sMCI_scans))])\n",
    "f5_sMCI_labels = np.array([0 for _ in range(len(f5_sMCI_scans))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation of the folds (named after the fold they leave for val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in train and validation are 299 and 74.\n"
     ]
    }
   ],
   "source": [
    "#Fold 1\n",
    "x_train = np.concatenate((f2_pMCI_scans,f3_pMCI_scans,f4_pMCI_scans,f5_pMCI_scans,\n",
    "                          f2_sMCI_scans,f3_sMCI_scans,f4_sMCI_scans,f5_sMCI_scans),axis=0)\n",
    "y_train = np.concatenate((f2_pMCI_labels,f3_pMCI_labels,f4_pMCI_labels,f5_pMCI_labels,\n",
    "                          f2_sMCI_labels,f3_sMCI_labels,f4_sMCI_labels,f5_sMCI_labels), axis=0)\n",
    "\n",
    "x_val = np.concatenate((f1_pMCI_scans,f1_sMCI_scans),axis=0)\n",
    "y_val = np.concatenate((f1_pMCI_labels,f1_sMCI_labels), axis=0)\n",
    "\n",
    "print(\n",
    "    \"Number of samples in train and validation are %d and %d.\"\n",
    "    % (x_train.shape[0], x_val.shape[0])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1train_loader = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "f1validation_loader = tf.data.Dataset.from_tensor_slices((x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.experimental.save(f1train_loader, \"./datasets/fold1train2\")\n",
    "\n",
    "tf.data.experimental.save(f1validation_loader, \"./datasets/fold1val2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=f1train_loader.element_spec\n",
    "with open('f1spec2.pickle', 'wb') as f:\n",
    "    pickle.dump(a, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in train and validation are 299 and 74.\n"
     ]
    }
   ],
   "source": [
    "#Fold 2\n",
    "x_train2 = np.concatenate((f1_pMCI_scans,f3_pMCI_scans,f4_pMCI_scans,f5_pMCI_scans,\n",
    "                          f1_sMCI_scans,f3_sMCI_scans,f4_sMCI_scans,f5_sMCI_scans),axis=0)\n",
    "y_train2 = np.concatenate((f1_pMCI_labels,f3_pMCI_labels,f4_pMCI_labels,f5_pMCI_labels,\n",
    "                          f1_sMCI_labels,f3_sMCI_labels,f4_sMCI_labels,f5_sMCI_labels), axis=0)\n",
    "\n",
    "x_val2 = np.concatenate((f2_pMCI_scans,f2_sMCI_scans),axis=0)\n",
    "y_val2 = np.concatenate((f2_pMCI_labels,f2_sMCI_labels), axis=0)\n",
    "\n",
    "print(\n",
    "    \"Number of samples in train and validation are %d and %d.\"\n",
    "    % (x_train2.shape[0], x_val2.shape[0])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2train_loader = tf.data.Dataset.from_tensor_slices((x_train2, y_train2))\n",
    "f2validation_loader = tf.data.Dataset.from_tensor_slices((x_val2, y_val2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.experimental.save(f1train_loader, \"./datasets/fold2train2\")\n",
    "\n",
    "tf.data.experimental.save(f1validation_loader, \"./datasets/fold2val2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=f2train_loader.element_spec\n",
    "with open('f2spec2.pickle', 'wb') as f:\n",
    "    pickle.dump(a, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in train and validation are 299 and 74.\n"
     ]
    }
   ],
   "source": [
    "#Fold 3\n",
    "x_train3 = np.concatenate((f2_pMCI_scans,f1_pMCI_scans,f4_pMCI_scans,f5_pMCI_scans,\n",
    "                          f2_sMCI_scans,f1_sMCI_scans,f4_sMCI_scans,f5_sMCI_scans),axis=0)\n",
    "y_train3 = np.concatenate((f2_pMCI_labels,f1_pMCI_labels,f4_pMCI_labels,f5_pMCI_labels,\n",
    "                          f2_sMCI_labels,f1_sMCI_labels,f4_sMCI_labels,f5_sMCI_labels), axis=0)\n",
    "\n",
    "x_val3 = np.concatenate((f3_pMCI_scans,f3_sMCI_scans),axis=0)\n",
    "y_val3 = np.concatenate((f3_pMCI_labels,f3_sMCI_labels), axis=0)\n",
    "\n",
    "print(\n",
    "    \"Number of samples in train and validation are %d and %d.\"\n",
    "    % (x_train3.shape[0], x_val3.shape[0])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "f3train_loader = tf.data.Dataset.from_tensor_slices((x_train3, y_train3))\n",
    "f3validation_loader = tf.data.Dataset.from_tensor_slices((x_val3, y_val3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.experimental.save(f3train_loader, \"./datasets/fold3train2\")\n",
    "\n",
    "tf.data.experimental.save(f3validation_loader, \"./datasets/fold3val2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=f3train_loader.element_spec\n",
    "with open('f3spec2.pickle', 'wb') as f:\n",
    "    pickle.dump(a, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in train and validation are 299 and 74.\n"
     ]
    }
   ],
   "source": [
    "#Fold 4\n",
    "x_train4 = np.concatenate((f2_pMCI_scans,f3_pMCI_scans,f1_pMCI_scans,f5_pMCI_scans,\n",
    "                          f2_sMCI_scans,f3_sMCI_scans,f1_sMCI_scans,f5_sMCI_scans),axis=0)\n",
    "y_train4 = np.concatenate((f2_pMCI_labels,f3_pMCI_labels,f1_pMCI_labels,f5_pMCI_labels,\n",
    "                          f2_sMCI_labels,f3_sMCI_labels,f1_sMCI_labels,f5_sMCI_labels), axis=0)\n",
    "\n",
    "x_val4 = np.concatenate((f4_pMCI_scans,f4_sMCI_scans),axis=0)\n",
    "y_val4 = np.concatenate((f4_pMCI_labels,f4_sMCI_labels), axis=0)\n",
    "\n",
    "print(\n",
    "    \"Number of samples in train and validation are %d and %d.\"\n",
    "    % (x_train4.shape[0], x_val4.shape[0])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "f4train_loader = tf.data.Dataset.from_tensor_slices((x_train4, y_train4))\n",
    "f4validation_loader = tf.data.Dataset.from_tensor_slices((x_val4, y_val4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.experimental.save(f4train_loader, \"./datasets/fold4train2\")\n",
    "\n",
    "tf.data.experimental.save(f4validation_loader, \"./datasets/fold4val2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=f4train_loader.element_spec\n",
    "with open('f4spec2.pickle', 'wb') as f:\n",
    "    pickle.dump(a, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in train and validation are 296 and 77.\n"
     ]
    }
   ],
   "source": [
    "#Fold 5\n",
    "x_train5 = np.concatenate((f2_pMCI_scans,f3_pMCI_scans,f4_pMCI_scans,f1_pMCI_scans,\n",
    "                          f2_sMCI_scans,f3_sMCI_scans,f4_sMCI_scans,f1_sMCI_scans),axis=0)\n",
    "y_train5 = np.concatenate((f2_pMCI_labels,f3_pMCI_labels,f4_pMCI_labels,f1_pMCI_labels,\n",
    "                          f2_sMCI_labels,f3_sMCI_labels,f4_sMCI_labels,f1_sMCI_labels), axis=0)\n",
    "\n",
    "x_val5 = np.concatenate((f5_pMCI_scans,f5_sMCI_scans),axis=0)\n",
    "y_val5 = np.concatenate((f5_pMCI_labels,f5_sMCI_labels), axis=0)\n",
    "\n",
    "print(\n",
    "    \"Number of samples in train and validation are %d and %d.\"\n",
    "    % (x_train5.shape[0], x_val5.shape[0])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "f5train_loader = tf.data.Dataset.from_tensor_slices((x_train5, y_train5))\n",
    "f5validation_loader = tf.data.Dataset.from_tensor_slices((x_val5, y_val5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.experimental.save(f5train_loader, \"./datasets/fold5train2\")\n",
    "\n",
    "tf.data.experimental.save(f5validation_loader, \"./datasets/fold5val2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=f5train_loader.element_spec\n",
    "with open('f5spec2.pickle', 'wb') as f:\n",
    "    pickle.dump(a, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
